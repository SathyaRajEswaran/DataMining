{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c6ecf-cd1b-4d99-b722-d28d166c934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title: Week 10.2: Project Milestone 3: Model Building and Evaluation\n",
    "#Author: Brett Werner\n",
    "#Date: 16 Nov 2025\n",
    "#Created By: Sathya Raj Eswaran\n",
    "#Description: Project Milestone 3: Model Building and Evaluation\n",
    "#==========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44a9b9ad-8274-4392-952e-1d92f57310b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d91f029-ae6b-45df-841e-15870c91dab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded\n",
      "\n",
      "First 5 rows of the DataFrame:\n",
      "   Customer ID  Gender  Age           City Membership Type  Total Spend  \\\n",
      "0          101  Female   29       New York            Gold      1120.20   \n",
      "1          102    Male   34    Los Angeles          Silver       780.50   \n",
      "2          103  Female   43        Chicago          Bronze       510.75   \n",
      "3          104    Male   30  San Francisco            Gold      1480.30   \n",
      "4          105    Male   27          Miami          Silver       720.40   \n",
      "\n",
      "   Items Purchased  Average Rating  Discount Applied  \\\n",
      "0               14             4.6              True   \n",
      "1               11             4.1             False   \n",
      "2                9             3.4              True   \n",
      "3               19             4.7             False   \n",
      "4               13             4.0              True   \n",
      "\n",
      "   Days Since Last Purchase Satisfaction Level  \n",
      "0                        25          Satisfied  \n",
      "1                        18            Neutral  \n",
      "2                        42        Unsatisfied  \n",
      "3                        12          Satisfied  \n",
      "4                        55        Unsatisfied  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"data\\\\E-commerce Customer Behavior Dataset.csv\")\n",
    "# Display the first 5 rows to visually inspect the data.\n",
    "print(f\"Successfully loaded\")\n",
    "print(\"\\nFirst 5 rows of the DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e2f50be-72a4-41d4-aa8e-4555720e38d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Row Count: 350\n",
      "Final Row Count (after dropping 2 NaNs): 348\n",
      "\n",
      "Final Data Info:\n"
     ]
    }
   ],
   "source": [
    "# 1. Data Cleaning\n",
    "# Drop rows with missing 'Satisfaction Level'\n",
    "\n",
    "print(f\"Original Row Count: {len(df)}\")\n",
    "df_temp = df.dropna(subset=['Satisfaction Level']).copy()\n",
    "\n",
    "print(f\"Final Row Count (after dropping 2 NaNs): {len(df_temp)}\")\n",
    "print(\"\\nFinal Data Info:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28dd3c44-466a-4467-a163-ea6870a1c0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the feature to drop\n",
    "features_to_drop = ['Customer ID']\n",
    "\n",
    "# Drop the non-useful feature\n",
    "df_dropped = df_temp.drop(columns=features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27801b00-0268-4acc-ace7-d1ceddfa72f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features dropped: Customer ID\n",
      "\n",
      "First 5 rows of the DataFrame after dropping 'Customer ID':\n",
      "| Gender   | Age   | City          | Membership Type   | Total Spend   | Items Purchased   | Average Rating   | Discount Applied   | Days Since Last Purchase   | Satisfaction Level   |\n",
      "|:---------|:------|:--------------|:------------------|:--------------|:------------------|:-----------------|:-------------------|:---------------------------|:---------------------|\n",
      "| Female   | 29    | New York      | Gold              | 1120.2        | 14                | 4.6              | True               | 25                         | Satisfied            |\n",
      "| Male     | 34    | Los Angeles   | Silver            | 780.5         | 11                | 4.1              | False              | 18                         | Neutral              |\n",
      "| Female   | 43    | Chicago       | Bronze            | 510.75        | 9                 | 3.4              | True               | 42                         | Unsatisfied          |\n",
      "| Male     | 30    | San Francisco | Gold              | 1480.3        | 19                | 4.7              | False              | 12                         | Satisfied            |\n",
      "| Male     | 27    | Miami         | Silver            | 720.4         | 13                | 4                | True               | 55                         | Unsatisfied          |\n",
      "\n",
      "Shape of the DataFrame before dropping: (350, 11)\n",
      "Shape of the DataFrame after dropping: (348, 10)\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows of the new DataFrame to confirm the drop\n",
    "print(f\"Features dropped: {'Customer ID'}\")\n",
    "print(\"\\nFirst 5 rows of the DataFrame after dropping 'Customer ID':\")\n",
    "print(df_dropped.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "print(\"\\nShape of the DataFrame before dropping:\", df.shape)\n",
    "print(\"Shape of the DataFrame after dropping:\", df_dropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e30bada-1445-4e60-ac79-bfabf5dbd040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 348 entries, 0 to 349\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Gender                    348 non-null    object \n",
      " 1   Age                       348 non-null    int64  \n",
      " 2   City                      348 non-null    object \n",
      " 3   Membership Type           348 non-null    object \n",
      " 4   Total Spend               348 non-null    float64\n",
      " 5   Items Purchased           348 non-null    int64  \n",
      " 6   Average Rating            348 non-null    float64\n",
      " 7   Discount Applied          348 non-null    int32  \n",
      " 8   Days Since Last Purchase  348 non-null    int64  \n",
      " 9   Satisfaction Level        348 non-null    object \n",
      "dtypes: float64(2), int32(1), int64(3), object(4)\n",
      "memory usage: 28.5+ KB\n",
      "None\n",
      "\n",
      "First 5 rows of the Final Cleaned DataFrame:\n",
      "| Gender   | Age   | City          | Membership Type   | Total Spend   | Items Purchased   | Average Rating   | Discount Applied   | Days Since Last Purchase   | Satisfaction Level   |\n",
      "|:---------|:------|:--------------|:------------------|:--------------|:------------------|:-----------------|:-------------------|:---------------------------|:---------------------|\n",
      "| Female   | 29    | New York      | Gold              | 1120.2        | 14                | 4.6              | 1                  | 25                         | Satisfied            |\n",
      "| Male     | 34    | Los Angeles   | Silver            | 780.5         | 11                | 4.1              | 0                  | 18                         | Neutral              |\n",
      "| Female   | 43    | Chicago       | Bronze            | 510.75        | 9                 | 3.4              | 1                  | 42                         | Unsatisfied          |\n",
      "| Male     | 30    | San Francisco | Gold              | 1480.3        | 19                | 4.7              | 0                  | 12                         | Satisfied            |\n",
      "| Male     | 27    | Miami         | Silver            | 720.4         | 13                | 4                | 1                  | 55                         | Unsatisfied          |\n"
     ]
    }
   ],
   "source": [
    "# 2. Convert 'Discount Applied' from boolean to integer (0 or 1) for modeling\n",
    "df_dropped['Discount Applied'] = df_dropped['Discount Applied'].astype(int)\n",
    "print(df_dropped.info())\n",
    "print(\"\\nFirst 5 rows of the Final Cleaned DataFrame:\")\n",
    "print(df_dropped.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af14a982-60ac-46d9-9d79-c0863572a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Transformation (Encoding) ---\n",
    "\n",
    "# 5. One-Hot Encoding for nominal features: 'Gender' and 'City'\n",
    "# 'drop_first=True' is used to avoid multicollinearity.\n",
    "df_F = pd.get_dummies(df_dropped, columns=['Gender', 'City'], drop_first=True)\n",
    "\n",
    "# 6. Ordinal Encoding for 'Membership Type' (assuming a logical order: Bronze < Silver < Gold)\n",
    "membership_order = {'Bronze': 1, 'Silver': 2, 'Gold': 3}\n",
    "df_F['Membership Type Encoded'] = df_F['Membership Type'].map(membership_order)\n",
    "df_F = df_F.drop(columns=['Membership Type'])\n",
    "\n",
    "# 7. Label Encoding for the target variable 'Satisfaction Level'\n",
    "# (Assigning levels: 0=Unsatisfied, 1=Neutral, 2=Satisfied)\n",
    "satisfaction_order = {'Unsatisfied': 0, 'Neutral': 1, 'Satisfied': 2}\n",
    "df_F['Satisfaction Level Encoded'] = df_F['Satisfaction Level'].map(satisfaction_order)\n",
    "df_F = df_F.drop(columns=['Satisfaction Level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a554bc5-b865-4586-aa1b-819cc6ef0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Discount Applied' from boolean (True/False) to integer (1/0)\n",
    "df_F['Discount Applied'] = df_F['Discount Applied'].astype(int)\n",
    "\n",
    "# 3. Engineer New Useful Features (RFM-derived metrics)\n",
    "# Average Item Price: Captures the customer's value segment (how expensive their items are)\n",
    "df_F['Average_Item_Price'] = df_F['Total Spend'] / (df_F['Items Purchased'])\n",
    "\n",
    "# Engagement Score: Measures frequency/volume relative to recency\n",
    "df_F['Engagement_Score'] = df_F['Items Purchased'] / (df_F['Days Since Last Purchase'] )\n",
    "\n",
    "# Recency Value Ratio: Measures monetary value relative to recency (high-value, active customer)\n",
    "df_F['Recency_Value_Ratio'] = df_F['Total Spend'] / (df_F['Days Since Last Purchase'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "296260a5-0ea8-4ee3-9f9d-a85d4dc0a213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Total Spend</th>\n",
       "      <th>Items Purchased</th>\n",
       "      <th>Average Rating</th>\n",
       "      <th>Discount Applied</th>\n",
       "      <th>Days Since Last Purchase</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>City_Houston</th>\n",
       "      <th>City_Los Angeles</th>\n",
       "      <th>City_Miami</th>\n",
       "      <th>City_New York</th>\n",
       "      <th>City_San Francisco</th>\n",
       "      <th>Membership Type Encoded</th>\n",
       "      <th>Satisfaction Level Encoded</th>\n",
       "      <th>Average_Item_Price</th>\n",
       "      <th>Engagement_Score</th>\n",
       "      <th>Recency_Value_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>1120.20</td>\n",
       "      <td>14</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>80.014286</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>44.808000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>780.50</td>\n",
       "      <td>11</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>70.954545</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>43.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>510.75</td>\n",
       "      <td>9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.750000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>12.160714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>1480.30</td>\n",
       "      <td>19</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>77.910526</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>123.358333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>720.40</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>55.415385</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>13.098182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Total Spend  Items Purchased  Average Rating  Discount Applied  \\\n",
       "0   29      1120.20               14             4.6                 1   \n",
       "1   34       780.50               11             4.1                 0   \n",
       "2   43       510.75                9             3.4                 1   \n",
       "3   30      1480.30               19             4.7                 0   \n",
       "4   27       720.40               13             4.0                 1   \n",
       "\n",
       "   Days Since Last Purchase  Gender_Male  City_Houston  City_Los Angeles  \\\n",
       "0                        25        False         False             False   \n",
       "1                        18         True         False              True   \n",
       "2                        42        False         False             False   \n",
       "3                        12         True         False             False   \n",
       "4                        55         True         False             False   \n",
       "\n",
       "   City_Miami  City_New York  City_San Francisco  Membership Type Encoded  \\\n",
       "0       False           True               False                        3   \n",
       "1       False          False               False                        2   \n",
       "2       False          False               False                        1   \n",
       "3       False          False                True                        3   \n",
       "4        True          False               False                        2   \n",
       "\n",
       "   Satisfaction Level Encoded  Average_Item_Price  Engagement_Score  \\\n",
       "0                           2           80.014286          0.560000   \n",
       "1                           1           70.954545          0.611111   \n",
       "2                           0           56.750000          0.214286   \n",
       "3                           2           77.910526          1.583333   \n",
       "4                           0           55.415385          0.236364   \n",
       "\n",
       "   Recency_Value_Ratio  \n",
       "0            44.808000  \n",
       "1            43.361111  \n",
       "2            12.160714  \n",
       "3           123.358333  \n",
       "4            13.098182  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_F.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d31740b1-67b3-4336-a779-50b947687db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into: Train (243 samples), Test (105 samples)\n",
      "\n",
      "Numerical features scaled using StandardScaler.\n",
      "\n",
      "Logistic Regression model trained successfully.\n",
      "\n",
      "--- Evaluation Results (Logistic Regression Baseline) ---\n",
      "\n",
      "Overall Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Unsatisfied (0)       1.00      1.00      1.00        35\n",
      "    Neutral (1)       1.00      1.00      1.00        32\n",
      "  Satisfied (2)       1.00      1.00      1.00        38\n",
      "\n",
      "       accuracy                           1.00       105\n",
      "      macro avg       1.00      1.00      1.00       105\n",
      "   weighted avg       1.00      1.00      1.00       105\n",
      "\n",
      "\n",
      "Confusion Matrix (True Rows vs Predicted Columns):\n",
      "                      Pred Unsatisfied (0)  Pred Neutral (1)  \\\n",
      "True Unsatisfied (0)                    35                 0   \n",
      "True Neutral (1)                         0                32   \n",
      "True Satisfied (2)                       0                 0   \n",
      "\n",
      "                      Pred Satisfied (2)  \n",
      "True Unsatisfied (0)                   0  \n",
      "True Neutral (1)                       0  \n",
      "True Satisfied (2)                    38  \n",
      "\n",
      "Top 5 Feature Importances (Absolute Coefficients for Class 1 vs Class 0):\n",
      "|                          | Coeff (Class 1 vs 0)   |\n",
      "|:-------------------------|:-----------------------|\n",
      "| Days Since Last Purchase | 1.46888                |\n",
      "| Discount Applied         | 1.10238                |\n",
      "| City_Houston             | -0.764374              |\n",
      "| City_Miami               | 0.741333               |\n",
      "| Average_Item_Price       | -0.563621              |\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Data Splitting (Train/Test) ---\n",
    "\n",
    "# Define Features (X) and Target (y)\n",
    "X = df_F.drop('Satisfaction Level Encoded', axis=1)\n",
    "y = df_F['Satisfaction Level Encoded']\n",
    "\n",
    "# Split the data (70% Train, 30% Test) and stratify to maintain class ratios\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Data split into: Train ({len(X_train)} samples), Test ({len(X_test)} samples)\")\n",
    "\n",
    "# --- 2. Feature Scaling (Mandatory for Logistic Regression) ---\n",
    "\n",
    "# Identify numerical columns for scaling\n",
    "numerical_cols = [\n",
    "    'Age', 'Total Spend', 'Items Purchased', 'Average Rating',\n",
    "    'Days Since Last Purchase', 'Average_Item_Price',\n",
    "    'Engagement_Score', 'Recency_Value_Ratio'\n",
    "]\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create copies for scaling\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Fit scaler only on the training data and transform both sets\n",
    "X_train_scaled[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test_scaled[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "print(\"\\nNumerical features scaled using StandardScaler.\")\n",
    "\n",
    "# --- 3. Model Training (Logistic Regression Baseline) ---\n",
    "\n",
    "# Initialize the Logistic Regression Model\n",
    "log_reg = LogisticRegression(\n",
    "    solver='lbfgs',      # Default solver, good for small datasets\n",
    "    multi_class='auto',  # Handles 3+ classes\n",
    "    max_iter=1000,       # Increased iterations for robust convergence\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on the scaled training data\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nLogistic Regression model trained successfully.\")\n",
    "\n",
    "# --- 4. Model Evaluation ---\n",
    "\n",
    "# Make predictions on the scaled test set\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "print(f\"\\n--- Evaluation Results (Logistic Regression Baseline) ---\\n\")\n",
    "\n",
    "# 4.1. Accuracy Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "# 4.2. Classification Report (F1-Score, Precision, Recall)\n",
    "target_names = ['Unsatisfied (0)', 'Neutral (1)', 'Satisfied (2)']\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# 4.3. Confusion Matrix (Visualizing Errors)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix (True Rows vs Predicted Columns):\")\n",
    "print(pd.DataFrame(conf_matrix,\n",
    "                   index=['True ' + name for name in target_names],\n",
    "                   columns=['Pred ' + name for name in target_names]))\n",
    "\n",
    "# 4.4. Feature Importance (from coefficients for the first class, Unsatisfied)\n",
    "# Note: Coefficients are calculated for each class relative to the reference class (often Unsatisfied=0)\n",
    "# Here, we only look at the coefficients for predicting class 1 (Neutral) vs class 0 (Unsatisfied) for simplicity.\n",
    "coefficients_df = pd.DataFrame(log_reg.coef_[0], index=X_train_scaled.columns, columns=['Coeff (Class 1 vs 0)'])\n",
    "coefficients_df['Absolute Value'] = coefficients_df['Coeff (Class 1 vs 0)'].abs()\n",
    "coefficients_df = coefficients_df.sort_values(by='Absolute Value', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Feature Importances (Absolute Coefficients for Class 1 vs Class 0):\")\n",
    "print(coefficients_df.head(5)[['Coeff (Class 1 vs 0)']].to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560adb5c-bc32-4775-9f51-aadfdbbaae31",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9084d519-b2bc-4cc7-9abe-be00342b523f",
   "metadata": {},
   "source": [
    "The model-building phase used a Logistic Regression classifier to predict customer satisfaction levels (Unsatisfied, Neutral, Satisfied). The evaluation phase provided two key insights: an exceptionally high-performing model and a set of important features driving the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a51cc-4ca7-42a0-8bd8-2d86d28e53f1",
   "metadata": {},
   "source": [
    "### Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b34a67-7cc1-46da-925c-406640d6f8b3",
   "metadata": {},
   "source": [
    "The Logistic Regression model achieved $\\mathbf{100.00\\%}$ accuracy on the test set. All other metrics (precision, recall, and F1-score) for all three classes were also perfect at $\\mathbf{1.00}$. The confusion matrix showed zero misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74959fc-7244-4cbc-87d9-e22e4d517d37",
   "metadata": {},
   "source": [
    "### Confusion Matrix Layout:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd672d3-3339-45f0-9345-314b1851f8fa",
   "metadata": {},
   "source": [
    "\n",
    "| True Rows \\ Predicted Columns | Pred Unsatisfied (0) | Pred Neutral (1) | Pred Satisfied (2) |\n",
    "|-------------------------------|----------------------|------------------|--------------------|\n",
    "| **True Unsatisfied (0)** | 35                   | 0                | 0                  |\n",
    "| **True Neutral (1)** | 0                    | 32               | 0                  |\n",
    "| **True Satisfied (2)** | 0                    | 0                | 38                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a326bd-b9c6-4bff-b3f7-38502187b0e8",
   "metadata": {},
   "source": [
    "### Conclusion on Performance: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99934b91-2824-4f78-9273-dab2649837fa",
   "metadata": {},
   "source": [
    "While this level of accuracy suggests a highly effective model, a $\\mathbf{100\\%}$ score in a real-world scenario is uncommon and strongly suggests a potential issue like data leakage, where a feature highly correlated or directly derived from the target variable was inadvertently included in the training data. This potential issue warrants further investigation to ensure the model's generalizability before deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c332d-f719-42b2-bf2a-ac5a1f414a09",
   "metadata": {},
   "source": [
    "### Key Feature Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d871af-6491-41da-be95-ce3b2e895915",
   "metadata": {},
   "source": [
    "The feature importance, derived from the absolute value of the model's coefficients (comparing the Neutral class to the Unsatisfied class), identified the following top drivers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5199dc6a-fb4c-49c3-9e85-0e741ce37e0c",
   "metadata": {},
   "source": [
    "### Feature Importance: Neutral (1) vs. Unsatisfied (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1aa209-a67f-48a7-8faf-50f4db1024c1",
   "metadata": {},
   "source": [
    "| Feature | Coeff (Class 1 vs 0) | Interpretation (Neutral vs. Unsatisfied) |\n",
    "|:---|:---:|:---|\n",
    "| **Days Since Last Purchase** | +1.469 | Most influential. A higher number of days since the last purchase is strongly associated with a **Neutral** satisfaction level over Unsatisfied. |\n",
    "| **Discount Applied** | +1.102 | Receiving a discount is positively associated with being **Neutral** over Unsatisfied. |\n",
    "| **City_Houston** | -0.764 | Customers from **Houston** are more likely to be **Unsatisfied** (negative coefficient) compared to Neutral. |\n",
    "| **City_Miami** | +0.741 | Customers from **Miami** are more likely to be **Neutral** (positive coefficient) compared to Unsatisfied. |\n",
    "| **Average_Item_Price** | -0.564 | A lower average item price is associated with being **Unsatisfied** (negative coefficient) compared to Neutral. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf45564-bb08-4ce3-8135-99e4787b2a99",
   "metadata": {},
   "source": [
    "### Conclusion on Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54306f20-a262-4edf-81e8-247996e239c5",
   "metadata": {},
   "source": [
    "Days Since Last Purchase and Discount Applied are the two most critical variables in distinguishing between Unsatisfied and Neutral customers. The significant presence of City as an important feature suggests that geographic location may play a non-trivial role in determining customer satisfaction, a finding that could inform targeted, localized marketing or service improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f1edd-8fe6-4de8-89fb-04d1464f2d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
