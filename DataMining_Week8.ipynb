{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad97e7e-239f-4af3-b802-6747a7883bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title: Week 8: Term Project Milestone 2: Data Preparation\n",
    "#Author: Brett Werner\n",
    "#Date: 02 Nov 2025\n",
    "#Created By: Sathya Raj Eswaran\n",
    "#Description: Term Project Milestone 2: Data Preparation\n",
    "#==========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1980be86-9f73-4913-b34d-31074882aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa0e50fc-b07e-4874-a5ea-f99787731c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded\n",
      "\n",
      "First 5 rows of the DataFrame:\n",
      "   Customer ID  Gender  Age           City Membership Type  Total Spend  \\\n",
      "0          101  Female   29       New York            Gold      1120.20   \n",
      "1          102    Male   34    Los Angeles          Silver       780.50   \n",
      "2          103  Female   43        Chicago          Bronze       510.75   \n",
      "3          104    Male   30  San Francisco            Gold      1480.30   \n",
      "4          105    Male   27          Miami          Silver       720.40   \n",
      "\n",
      "   Items Purchased  Average Rating  Discount Applied  \\\n",
      "0               14             4.6              True   \n",
      "1               11             4.1             False   \n",
      "2                9             3.4              True   \n",
      "3               19             4.7             False   \n",
      "4               13             4.0              True   \n",
      "\n",
      "   Days Since Last Purchase Satisfaction Level  \n",
      "0                        25          Satisfied  \n",
      "1                        18            Neutral  \n",
      "2                        42        Unsatisfied  \n",
      "3                        12          Satisfied  \n",
      "4                        55        Unsatisfied  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"data\\\\E-commerce Customer Behavior Dataset.csv\")\n",
    "# Display the first 5 rows to visually inspect the data.\n",
    "print(f\"Successfully loaded\")\n",
    "print(\"\\nFirst 5 rows of the DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "112610e3-acd0-44f8-82ea-6cb15e94311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Row Count: 350\n",
      "Final Row Count (after dropping 2 NaNs): 348\n",
      "\n",
      "Final Data Info:\n"
     ]
    }
   ],
   "source": [
    "# 1. Data Cleaning\n",
    "# Drop rows with missing 'Satisfaction Level'\n",
    "\n",
    "print(f\"Original Row Count: {len(df)}\")\n",
    "df_temp = df.dropna(subset=['Satisfaction Level']).copy()\n",
    "\n",
    "print(f\"Final Row Count (after dropping 2 NaNs): {len(df_temp)}\")\n",
    "print(\"\\nFinal Data Info:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fdc4fad-9d0b-4831-9922-5db99434f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the feature to drop\n",
    "features_to_drop = ['Customer ID']\n",
    "\n",
    "# Drop the non-useful feature\n",
    "df_dropped = df_temp.drop(columns=features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff9c267a-2d7e-46e4-8038-8518d3a55080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features dropped: Customer ID\n",
      "\n",
      "First 5 rows of the DataFrame after dropping 'Customer ID':\n",
      "| Gender   | Age   | City          | Membership Type   | Total Spend   | Items Purchased   | Average Rating   | Discount Applied   | Days Since Last Purchase   | Satisfaction Level   |\n",
      "|:---------|:------|:--------------|:------------------|:--------------|:------------------|:-----------------|:-------------------|:---------------------------|:---------------------|\n",
      "| Female   | 29    | New York      | Gold              | 1120.2        | 14                | 4.6              | True               | 25                         | Satisfied            |\n",
      "| Male     | 34    | Los Angeles   | Silver            | 780.5         | 11                | 4.1              | False              | 18                         | Neutral              |\n",
      "| Female   | 43    | Chicago       | Bronze            | 510.75        | 9                 | 3.4              | True               | 42                         | Unsatisfied          |\n",
      "| Male     | 30    | San Francisco | Gold              | 1480.3        | 19                | 4.7              | False              | 12                         | Satisfied            |\n",
      "| Male     | 27    | Miami         | Silver            | 720.4         | 13                | 4                | True               | 55                         | Unsatisfied          |\n",
      "\n",
      "Shape of the DataFrame before dropping: (350, 11)\n",
      "Shape of the DataFrame after dropping: (348, 10)\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows of the new DataFrame to confirm the drop\n",
    "print(f\"Features dropped: {'Customer ID'}\")\n",
    "print(\"\\nFirst 5 rows of the DataFrame after dropping 'Customer ID':\")\n",
    "print(df_dropped.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "print(\"\\nShape of the DataFrame before dropping:\", df.shape)\n",
    "print(\"Shape of the DataFrame after dropping:\", df_dropped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39bbcab-a4b4-452b-85d6-b374e84e7ec6",
   "metadata": {},
   "source": [
    "Explanation for Dropping the Feature\n",
    "Feature\tReason for Dropping\n",
    "Customer ID\tNon-Predictive Unique Identifier: This column assigns a unique number to each row/customer. It has no inherent predictive value for a machine learning model because its value is unique and arbitrary; it does not help the model generalize patterns to new, unseen customers. Using it would lead to overfitting and poor performance on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "918f0875-9c07-4349-b980-013c6993f344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 348 entries, 0 to 349\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Gender                    348 non-null    object \n",
      " 1   Age                       348 non-null    int64  \n",
      " 2   City                      348 non-null    object \n",
      " 3   Membership Type           348 non-null    object \n",
      " 4   Total Spend               348 non-null    float64\n",
      " 5   Items Purchased           348 non-null    int64  \n",
      " 6   Average Rating            348 non-null    float64\n",
      " 7   Discount Applied          348 non-null    int32  \n",
      " 8   Days Since Last Purchase  348 non-null    int64  \n",
      " 9   Satisfaction Level        348 non-null    object \n",
      "dtypes: float64(2), int32(1), int64(3), object(4)\n",
      "memory usage: 28.5+ KB\n",
      "None\n",
      "\n",
      "First 5 rows of the Final Cleaned DataFrame:\n",
      "| Gender   | Age   | City          | Membership Type   | Total Spend   | Items Purchased   | Average Rating   | Discount Applied   | Days Since Last Purchase   | Satisfaction Level   |\n",
      "|:---------|:------|:--------------|:------------------|:--------------|:------------------|:-----------------|:-------------------|:---------------------------|:---------------------|\n",
      "| Female   | 29    | New York      | Gold              | 1120.2        | 14                | 4.6              | 1                  | 25                         | Satisfied            |\n",
      "| Male     | 34    | Los Angeles   | Silver            | 780.5         | 11                | 4.1              | 0                  | 18                         | Neutral              |\n",
      "| Female   | 43    | Chicago       | Bronze            | 510.75        | 9                 | 3.4              | 1                  | 42                         | Unsatisfied          |\n",
      "| Male     | 30    | San Francisco | Gold              | 1480.3        | 19                | 4.7              | 0                  | 12                         | Satisfied            |\n",
      "| Male     | 27    | Miami         | Silver            | 720.4         | 13                | 4                | 1                  | 55                         | Unsatisfied          |\n"
     ]
    }
   ],
   "source": [
    "# 2. Convert 'Discount Applied' from boolean to integer (0 or 1) for modeling\n",
    "df_dropped['Discount Applied'] = df_dropped['Discount Applied'].astype(int)\n",
    "print(df_dropped.info())\n",
    "print(\"\\nFirst 5 rows of the Final Cleaned DataFrame:\")\n",
    "print(df_dropped.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450b55a7-00d2-4c9d-a459-1db7d764d717",
   "metadata": {},
   "source": [
    "Handled Missing Target Variable: The 2 rows with missing values in the crucial target column, Satisfaction Level, were dropped using dropna().. This is a safe and common practice when the number of missing values is minimal, ensuring a clean target for supervised learning. 2. Feature Transformation: The boolean feature Discount Applied was converted to an integer (1 for True, 0 for False) to ensure it is in a numerical format suitable for most machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce1da6be-7468-4b01-83dd-cb2ad88d818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Transformation (Encoding) ---\n",
    "\n",
    "# 5. One-Hot Encoding for nominal features: 'Gender' and 'City'\n",
    "# 'drop_first=True' is used to avoid multicollinearity.\n",
    "df_F = pd.get_dummies(df_dropped, columns=['Gender', 'City'], drop_first=True)\n",
    "\n",
    "# 6. Ordinal Encoding for 'Membership Type' (assuming a logical order: Bronze < Silver < Gold)\n",
    "membership_order = {'Bronze': 1, 'Silver': 2, 'Gold': 3}\n",
    "df_F['Membership Type Encoded'] = df_F['Membership Type'].map(membership_order)\n",
    "df_F = df_F.drop(columns=['Membership Type'])\n",
    "\n",
    "# 7. Label Encoding for the target variable 'Satisfaction Level'\n",
    "# (Assigning levels: 0=Unsatisfied, 1=Neutral, 2=Satisfied)\n",
    "satisfaction_order = {'Unsatisfied': 0, 'Neutral': 1, 'Satisfied': 2}\n",
    "df_F['Satisfaction Level Encoded'] = df_F['Satisfaction Level'].map(satisfaction_order)\n",
    "df_F = df_F.drop(columns=['Satisfaction Level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8eddde-eb52-4ac9-81a0-3671038c8f8c",
   "metadata": {},
   "source": [
    "The original categorical columns were transformed as follows:\n",
    "\n",
    "1. Nominal Feature Encoding (One-Hot Encoding)\n",
    "Nominal features are those without a clear intrinsic order. They were converted into binary (0 or 1) columns.\n",
    "\n",
    "Gender and City were One-Hot Encoded. The drop_first=True option was used to avoid multicollinearity (the Dummy Variable Trap).\n",
    "\n",
    "Gender was transformed into Gender_Male (Female is represented by Gender_Male=0).\n",
    "\n",
    "City was transformed into five new city columns (e.g., City_Houston, City_New York), with City_Chicago serving as the baseline (all city columns set to 0).\n",
    "\n",
    "2. Ordinal Feature Encoding\n",
    "Ordinal features have a meaningful, ranked order. They were mapped to integer values reflecting that order.\n",
    "\n",
    "Membership Type was Ordinal Encoded based on hierarchy:\n",
    "\n",
    "Bronze: 1\n",
    "\n",
    "Silver: 2\n",
    "\n",
    "Gold: 3\n",
    "\n",
    "The original Membership Type column was dropped and replaced with Membership Type Encoded.\n",
    "\n",
    "3. Target Variable Encoding (Label Encoding)\n",
    "The target variable for classification was converted to integers.\n",
    "\n",
    "Satisfaction Level was Label Encoded to define the classes for the model:\n",
    "\n",
    "Unsatisfied: 0\n",
    "\n",
    "Neutral: 1\n",
    "\n",
    "Satisfied: 2\n",
    "\n",
    "The original Satisfaction Level column was dropped and replaced with Satisfaction Level Encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12bbf31-51c5-4fb4-a57f-49c8b5dbe341",
   "metadata": {},
   "source": [
    "This code transformed the categorical data into numerical data suitable for machine learning:\n",
    "\n",
    "Gender and City were converted using One-Hot Encoding.\n",
    "\n",
    "Membership Type was converted using Ordinal Encoding (1, 2, 3).\n",
    "\n",
    "Satisfaction Level (the target) was converted using Label Encoding (0, 1, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f528f640-6897-484b-a88d-ec64a511d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Discount Applied' from boolean (True/False) to integer (1/0)\n",
    "df_F['Discount Applied'] = df_F['Discount Applied'].astype(int)\n",
    "\n",
    "# 3. Engineer New Useful Features (RFM-derived metrics)\n",
    "# Average Item Price: Captures the customer's value segment (how expensive their items are)\n",
    "df_F['Average_Item_Price'] = df_F['Total Spend'] / (df_F['Items Purchased'])\n",
    "\n",
    "# Engagement Score: Measures frequency/volume relative to recency\n",
    "df_F['Engagement_Score'] = df_F['Items Purchased'] / (df_F['Days Since Last Purchase'] )\n",
    "\n",
    "# Recency Value Ratio: Measures monetary value relative to recency (high-value, active customer)\n",
    "df_F['Recency_Value_Ratio'] = df_F['Total Spend'] / (df_F['Days Since Last Purchase'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81919b9d-864f-4ceb-ad0d-22a8526ed85b",
   "metadata": {},
   "source": [
    "New, highly useful features were engineered from the existing raw data, which often capture more meaningful customer behavior metrics than the original features alone. These new features are based on common e-commerce and RFM (Recency, Frequency, Monetary) analysis principles.The code performed the following feature engineering steps: New Engineered FeaturesNew FeatureFormulaE-commerce SignificanceAverage_Item_Price$\\text{Total Spend} / \\text{Items Purchased}$This captures the customer's value segment. Customers with a high average item price are likely high-end shoppers, which may strongly correlate with satisfaction and membership level.Engagement_Score$\\text{Items Purchased} / \\text{Days Since Last Purchase}$This is a measure of customer frequency/volume relative to their recency. A high score indicates a customer who buys a large number of items and does so frequently (low days since last purchase), suggesting high engagement.Recency_Value_Ratio$\\text{Total Spend} / \\text{Days Since Last Purchase}$This is a measure of the customer's monetary value relative to recency. A high ratio indicates a customer who spends a high amount and has purchased recently, suggesting a high-value, active customer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec8271a-33bd-4879-bad3-fa4dfd5e9fe8",
   "metadata": {},
   "source": [
    "New, highly useful features were engineered from the existing raw data, which often capture more meaningful customer behavior metrics than the original features alone. These new features are based on common e-commerce and RFM (Recency, Frequency, Monetary) analysis principles.\n",
    "\n",
    "The code performed the following feature engineering steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07f2e0e-0a57-43ce-95c1-fb9deff3cd6d",
   "metadata": {},
   "source": [
    "New FeatureFormulaE-commerce SignificanceAverage_Item_Price$\\text{Total Spend} / \\text{Items Purchased}$This captures the customer's value segment. Customers with a high average item price are likely high-end shoppers, which may strongly correlate with satisfaction and membership level.Engagement_Score$\\text{Items Purchased} / \\text{Days Since Last Purchase}$This is a measure of customer frequency/volume relative to their recency. A high score indicates a customer who buys a large number of items and does so frequently (low days since last purchase), suggesting high engagement.Recency_Value_Ratio$\\text{Total Spend} / \\text{Days Since Last Purchase}$This is a measure of the customer's monetary value relative to recency. A high ratio indicates a customer who spends a high amount and has purchased recently, suggesting a high-value, active customer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e0c151-e428-4405-8d54-99ecef1ef9dd",
   "metadata": {},
   "source": [
    "### Engineer new useful features\n",
    "|New Feature\t | Formula | E-commerce Significance\n",
    "|---|---|---|\n",
    "|Average_Item_Price | {Total Spend} / {Items Purchased} | This captures the customer's value segment. Customers with a high average item price are likely high-end shoppers, which may strongly correlate with satisfaction and membership level.|\n",
    "\n",
    "|Engagement_Score | {Items Purchased} / {Days Since Last Purchase} | This is a measure of customer frequency/volume relative to their recency. A high score indicates a customer who buys a large number of items and does so frequently (low days since last purchase), suggesting high engagement.|\n",
    "\n",
    "|Recency_Value_Ratio | {Total Spend} / {Days Since Last Purchase} | This is a measure of the customer's monetary value relative to recency. A high ratio indicates a customer who spends a high amount and has purchased recently, suggesting a high-value, active customer.|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c245ae6-67f2-49d8-8deb-e03619d19763",
   "metadata": {},
   "source": [
    "Deal with missing data (do not just drop rows or columns without justifying this)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e7ded1-c5ca-48c3-a745-1fac37e81a67",
   "metadata": {},
   "source": [
    "Satisfaction Level\tMissing Count : 2 (out of 350)\n",
    "\n",
    "Strategy : Drop rows\n",
    "\n",
    "Justification : Since Satisfaction Level is the target variable for classification, missing values must be handled carefully. Dropping the 2 rows with missing data is the most robust strategy because 2 rows represent only $0.57\\%$ of the total data. Dropping them prevents the risk of introducing bias or inaccuracy that would come from trying to impute a categorical target variable with such low frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5992d8b0-bb70-4f17-92ac-61a062970a66",
   "metadata": {},
   "source": [
    "The two rows with missing Satisfaction Level have been successfully dropped, resulting in a dataset with 348 rows and no missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c5e16-35aa-4584-aaea-2260f1dfa624",
   "metadata": {},
   "source": [
    "Create dummy variables if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e37bacd4-d975-4b3a-bfb8-20fe85e9bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Transformation Summary ---\n",
    "#\n",
    "# Original Feature     | Transformation        | New Column(s) Created         | Reason\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# Gender               | One-Hot Encoding      | Gender_Male                   | Nominal (no order), avoids multicollinearity by using Female as the baseline.\n",
    "# City                 | One-Hot Encoding      | City_Houston, City_Los Angeles, etc. | Nominal (no order), with Chicago being the baseline (when all city dummies are 0).\n",
    "# Membership Type      | Ordinal Encoding      | Membership Type Encoded (1, 2, 3)    | Ordinal (clear order: Bronze < Silver < Gold).\n",
    "# Satisfaction Level   | Label Encoding        | Satisfaction Level Encoded (0, 1, 2) | Target variable encoding for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c59820-c040-4111-9041-054f1d59e978",
   "metadata": {},
   "source": [
    "This explanation summarizes the complete data preprocessing workflow (covering feature selection, missing data handling, feature engineering, and transformation) performed on the E-commerce Customer Behavior Dataset to prepare it for a machine learning classification model (likely predicting Satisfaction Level).\n",
    "\n",
    "\n",
    "The primary goal of this process was to ensure all data is in a numerical format, highly predictive, and free of issues like missing values or multicollinearity, adhering to the principle of avoiding data snooping by transforming features before model training.\n",
    "\n",
    "Step 1: Feature Selection (Dropping Non-Useful Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90b6ff19-d3ad-422a-bad1-8d545fff9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: Customer ID | Action: Dropped | Justification: This is a unique, arbitrary identifier with no predictive value. Retaining it would lead to model overfitting and prevent generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f471e899-f612-431d-a825-61c9dc1df22c",
   "metadata": {},
   "source": [
    "Step 2: Dealing with Missing DataInspection: An initial check revealed that only the Satisfaction Level column contained missing values (2 out of 350 rows).Action & Justification:Action: The 2 rows with missing Satisfaction Level were dropped.Justification: The Satisfaction Level is the target variable. Since 2 rows represent less than $1\\%$ of the dataset, dropping them is the safest and most robust strategy. Imputing a categorical target variable risks introducing bias that could skew the model's learning process. The remaining 348 rows are clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b4f5e-3cc2-44c0-b117-8506f8342570",
   "metadata": {},
   "source": [
    "Step 3: Feature Engineering (Creating Predictive Variables)\n",
    "New features were engineered based on established e-commerce metrics (like RFM: Recency, Frequency, Monetary) to capture deeper insights into customer behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0775496b-446c-41c5-bdb0-7290dc1548ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Feature: Average_Item_Price | Formula: Total Spend / Items Purchased | Rationale: Measures customer value segment (budget vs. luxury).\n",
    "# New Feature: Engagement_Score | Formula: Items Purchased / Days Since Last Purchase | Rationale: Measures customer activity/frequency. Higher score = more engaged.\n",
    "# New Feature: Recency_Value_Ratio | Formula: Total Spend / Days Since Last Purchase | Rationale: Measures monetary value per day of inactivity, combining Recency and Monetary metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e9663-9929-4298-bb35-624a450b16e1",
   "metadata": {},
   "source": [
    "Step 4: Feature Transformation and Encoding (Preparing for Modeling)\n",
    "All remaining non-numerical features were converted into a numerical format suitable for machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d8c12-ef37-495b-a582-7bae001de7cb",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Feature Transformation and Encoding Summary:\n",
    "\n",
    "| Original Feature | Action Taken | Rationale |\n",
    "|:---|:---|:---|\n",
    "| Discount Applied | Converted from Boolean to Integer | Mapped boolean values (True/False) to integers (1/0) for direct numerical model input. |\n",
    "| Gender & City | One-Hot Encoding (Dummy Variables) | Nominal features (no intrinsic order) required binary columns. drop_first=True was used to prevent multicollinearity (Dummy Variable Trap). |\n",
    "| Membership Type | Ordinal Encoding | Ordinal feature ($\\text{Bronze} < \\text{Silver} < \\text{Gold}$) was mapped to integers ($0, 1, 2$) to preserve rank information. |\n",
    "| Satisfaction Level | Label Encoding (Target) | Categorical classes ($\\text{Unsatisfied}=0, \\text{Neutral}=1, \\text{Satisfied}=2$) were mapped to integers to prepare for a multi-class classification model. |\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a16941-a039-472e-bab6-b3a266b01d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
